ğŸ† Jigsaw Rate Severity of Toxic Comments
===
Kaggleâ˜ Jigsaw Rate Severity of Toxic CommentsRank relative ratings of toxicity between comments!      
ì•…ì„± ëŒ“ê¸€ì˜ ë…ì„± ì •ë„ë¥¼ ì¸¡ì •í•˜ì—¬ scoreë¥¼ ì£¼ëŠ” í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.


# 1. Preprocessing
* `Ruddit dataset`ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°ì…‹ì„ ë§Œë“ ë‹¤. 
* Ruddit datasetì—ëŠ” severity ì •ë„ê°€ ìˆ˜ì¹˜ë¡œ ë‚˜íƒ€ë‚´ì ¸ ìˆëŠ”ë°, ì´ ìˆ˜ì¹˜ë¥¼ í† ëŒ€ë¡œ less toxic comments, more toxic commentsë¡œ ë‚˜ëˆˆë‹¤.
* ì˜ˆì‹œëŠ” ì•„ë˜ì™€ ê°™ë‹¤.    
![image](https://user-images.githubusercontent.com/74829786/177865875-e9d7ad31-5171-40e0-a5ca-d20a9f901d67.png)


# 2. Model
* ë‘ ê°œì˜ roberta-base ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ less toxic commentsì™€ more toxic commentsì˜ scoreë¥¼ ì˜ˆì¸¡í•œë‹¤.
* ì´ ë‘ ëª¨ë¸ì€ ê°€ì¤‘ì¹˜ë¥¼ ê³µìœ í•œë‹¤.

***


### ğŸ’¡ ì‹¤í–‰ ë°©ë²•

#### 1. Data Preprocessing
```python
$ python preprocessing.py \
  --train_path =TRAIN_DATASET_PATH
  --test_size  =0.1
  --max_len    =MAX_TOKEN_LENGTH  # 256
```

#### 2. Training
```python
$ python train.py \
  --epochs =10
```
